\documentclass[12pt,letterpaper]{article}

% Packages
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage[margin=1in]{geometry}
\usepackage{natbib}
\usepackage{setspace}
\usepackage{float}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{xcolor}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{lineno}

% Line numbers for review
\linenumbers

% Double spacing for review
\doublespacing

% Theorem environments
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{definition}{Definition}

% Custom commands
\newcommand{\E}{\mathbb{E}}
\newcommand{\Var}{\text{Var}}
\newcommand{\PAF}{\text{PAF}}
\newcommand{\RR}{\text{RR}}

\begin{document}

% Title Page
\title{Algorithmic Discrimination as Epidemiological Phenomenon: \\
A Mathematical Framework Revealing Synergistic Barrier Dynamics \\
and the Futility of Incremental Reform}

\author{AC Demidont, DO$^{1}$\\
\\
$^1$Nyx Dynamics LLC, United States\\
\\
Correspondence: acdemidont@nyxdynamics.org}

\date{January 2026}

\maketitle

\begin{abstract}
\noindent\textbf{Background:} Algorithmic systems increasingly mediate access to employment, housing, credit, and healthcare, yet the population-level dynamics of algorithmic discrimination remain poorly characterized. We hypothesized that algorithmic bias exhibits epidemiological properties analogous to infectious disease, including integration dynamics, feedback amplification, and barrier synergies.

\noindent\textbf{Methods:} We developed an 11-barrier multiplicative model of algorithmic discrimination across three layers (Data Integration, Data Accuracy, Institutional) and analyzed barrier removal effects using counterfactual analysis, Shapley value decomposition, and ANOVA interaction modeling. We validated findings through comprehensive sensitivity analysis including one-at-a-time perturbation, Sobol global sensitivity indices, Morris elementary effects screening, and bootstrap confidence intervals (n=1,000). Signal-to-noise ratio analysis assessed robustness to parameter uncertainty.

\noindent\textbf{Results:} Baseline success probability through all barriers was 0.0018\%. Individual barrier removal produced negligible improvement (all effects $<$0.02\%). The three-way interaction between barrier layers accounted for 87.6\% of total effect variance, explaining the consistent failure of single-target interventions. Only complete barrier removal achieved meaningful improvement (95\%). Shapley value attribution identified Legal Knowledge Gap (11.5\%), Rapid Data Transmission (10.6\%), and Systemic Bias (10.3\%) as top contributors. All key findings demonstrated 100\% robustness across bootstrap samples. Signal-to-noise ratio remained positive ($>$0 dB) up to 25\% parameter uncertainty.

\noindent\textbf{Conclusions:} Algorithmic discrimination operates as a synergistic system where barriers reinforce each other, rendering incremental reform mathematically futile. The dominant three-way interaction (87.6\%) provides a quantitative explanation for why decades of piecemeal policy interventions have failed to reduce algorithmic discrimination. Effective intervention requires coordinated, comprehensive reform addressing all barrier layers simultaneously.

\noindent\textbf{Keywords:} algorithmic discrimination, epidemiological modeling, barrier analysis, synergistic interaction, sensitivity analysis, health disparities
\end{abstract}

\newpage

%==============================================================================
\section{Introduction}
%==============================================================================

Algorithmic systems have become the primary gatekeepers for fundamental life opportunities. Employment screening algorithms evaluate 75\% of resumes before human review \citep{fuller2021hidden}. Credit scoring systems determine access to housing, loans, and insurance for 260 million Americans \citep{cfpb2022}. Healthcare algorithms allocate care resources, with documented racial bias affecting millions of patients \citep{obermeyer2019dissecting}. Despite growing awareness and regulatory efforts spanning decades, algorithmic discrimination persists at population scale.

The persistence of algorithmic discrimination despite intervention efforts suggests that current approaches fundamentally misunderstand the problem's structure. Policy interventions typically target individual barriers---improving credit report accuracy through the Fair Credit Reporting Act, prohibiting employment discrimination through Title VII, addressing housing bias through the Fair Housing Act---yet discrimination continues largely unabated. This pattern mirrors the epidemiological concept of intervention failure in systems with strong synergistic interactions.

We propose an epidemiological framework for understanding algorithmic discrimination, drawing on parallels to infectious disease dynamics. Just as viral integration into host DNA creates irreversible genomic changes \citep{coffin2021retrovirology}, data integration across interconnected systems creates persistent disadvantage. Just as feedback loops amplify initial infections \citep{nowak2000virus}, scoring system feedback loops amplify initial adverse events. And just as drug resistance emerges from incomplete treatment \citep{volberding2010antiretroviral}, policy resistance emerges from incomplete reform.

The present study develops a mathematical model of algorithmic discrimination as an 11-barrier system and tests the hypothesis that barrier synergies explain the failure of incremental reform. We employ rigorous sensitivity analysis to validate findings and quantify the contribution of interaction effects to overall system behavior.

%==============================================================================
\section{Methods}
%==============================================================================

\subsection{Barrier Model Specification}

We modeled algorithmic discrimination as requiring successful passage through 11 sequential barriers organized into three layers:

\textbf{Layer 1: Data Integration Barriers}
\begin{enumerate}
    \item Cross-System Data Sharing (pass probability: 0.30)
    \item Multi-Database Flagging (pass probability: 0.25)
    \item Rapid Data Transmission (pass probability: 0.35)
\end{enumerate}

\textbf{Layer 2: Data Accuracy Barriers}
\begin{enumerate}
    \setcounter{enumi}{3}
    \item Error Correction Difficulty (pass probability: 0.40)
    \item Identity Verification Complexity (pass probability: 0.45)
    \item Systemic Bias in Algorithms (pass probability: 0.35)
\end{enumerate}

\textbf{Layer 3: Institutional Barriers}
\begin{enumerate}
    \setcounter{enumi}{6}
    \item Legal Knowledge Gap (pass probability: 0.20)
    \item Financial Resources for Advocacy (pass probability: 0.25)
    \item Time Constraints for Dispute (pass probability: 0.30)
    \item Retaliation Concerns (pass probability: 0.50)
    \item Procedural Complexity (pass probability: 0.35)
\end{enumerate}

Pass probabilities were estimated from empirical literature on FCRA dispute resolution rates \citep{wu2019}, employment screening error rates \citep{eeoc2012}, and legal aid utilization patterns \citep{lsc2022}.

\subsection{Mathematical Framework}

Under the multiplicative barrier model, the probability of successful cascade completion (resolving algorithmic discrimination) is:

\begin{equation}
P(\text{success}) = \prod_{i=1}^{11} p_i
\end{equation}

where $p_i$ is the pass probability for barrier $i$. With our parameterization:

\begin{equation}
P(\text{success}) = 0.30 \times 0.25 \times \cdots \times 0.35 = 1.8 \times 10^{-5} \approx 0.0018\%
\end{equation}

The effect of removing barrier $j$ is:

\begin{equation}
\Delta_j = P(\text{success}|p_j=1) - P(\text{success}) = \prod_{i \neq j} p_i - \prod_{i=1}^{11} p_i
\end{equation}

\subsection{Shapley Value Attribution}

To fairly attribute system effect to individual barriers accounting for interaction structure, we employed Shapley value decomposition from cooperative game theory \citep{shapley1953value}:

\begin{equation}
\phi_i = \sum_{S \subseteq N \setminus \{i\}} \frac{|S|!(n-|S|-1)!}{n!} [v(S \cup \{i\}) - v(S)]
\end{equation}

where $v(S)$ is the success probability when barriers in coalition $S$ are removed, $N$ is the set of all barriers, and $n = |N| = 11$. Shapley values were computed over $n=1,000$ sampled permutations of barrier removal orderings.

\subsection{Interaction Effect Analysis}

We performed $2^3$ factorial analysis of layer-level removal to quantify main effects and interactions:

\begin{equation}
y = \mu + \alpha_1 L_1 + \alpha_2 L_2 + \alpha_3 L_3 + \beta_{12} L_1 L_2 + \beta_{13} L_1 L_3 + \beta_{23} L_2 L_3 + \gamma_{123} L_1 L_2 L_3 + \epsilon
\end{equation}

where $L_i \in \{0, 1\}$ indicates whether layer $i$ is removed, and $\gamma_{123}$ captures the three-way interaction.

\subsection{Sensitivity Analysis}

\subsubsection{One-at-a-Time (OAT) Sensitivity}

For each barrier parameter $p_i$, we computed normalized sensitivity indices:

\begin{equation}
S_i = \frac{\partial P(\text{success})}{\partial p_i} \cdot \frac{p_i}{P(\text{success})}
\end{equation}

evaluated via finite differences with $\pm 10\%$ perturbation.

\subsubsection{Sobol Global Sensitivity Indices}

Variance-based sensitivity analysis decomposed output variance into contributions from individual parameters and their interactions \citep{sobol2001global}:

\begin{equation}
V(Y) = \sum_i V_i + \sum_{i<j} V_{ij} + \cdots + V_{1,2,\ldots,k}
\end{equation}

First-order indices $S_i = V_i/V(Y)$ measure individual parameter contributions; total-order indices $S_{T_i}$ include all interaction effects involving parameter $i$. We used Saltelli sampling with $n=1,024$ base samples.

\subsubsection{Morris Elementary Effects Screening}

The Morris method \citep{morris1991factorial} computes elementary effects across $r=20$ trajectories:

\begin{equation}
EE_i = \frac{y(x_1, \ldots, x_i + \Delta, \ldots, x_k) - y(x_1, \ldots, x_k)}{\Delta}
\end{equation}

Mean absolute effect $\mu^*_i$ indicates parameter importance; standard deviation $\sigma_i$ indicates nonlinearity or interaction involvement.

\subsubsection{Bootstrap Validation}

We generated $n=1,000$ bootstrap samples with 30\% multiplicative noise on parameters to assess key finding robustness:

\begin{enumerate}
    \item Three-way interaction dominance ($>70\%$ of total effect)
    \item Individual barrier effects near zero ($<1\%$)
    \item Barriers required for 90\% success ($\geq 10$)
\end{enumerate}

\subsubsection{Signal-to-Noise Ratio Analysis}

We computed SNR under varying noise levels (1\%--30\%):

\begin{equation}
\text{SNR}_{dB} = 10 \log_{10} \left( \frac{\mu^2}{\sigma^2} \right)
\end{equation}

where $\mu$ and $\sigma$ are mean and standard deviation of model output under noise injection.

\subsection{Population Attributable Fraction}

For affected subpopulations, we calculated PAF using Levin's formula \citep{levin1953occurrence}:

\begin{equation}
\PAF = \frac{P_e(\RR - 1)}{1 + P_e(\RR - 1)}
\end{equation}

where $P_e$ is prevalence of algorithmic exposure and $\RR$ is relative risk of adverse outcome.

\subsection{Software and Reproducibility}

All analyses were conducted in Python 3.10+ using NumPy, SciPy, Matplotlib, and SALib \citep{herman2017salib}. Random seed was fixed at 42 for reproducibility. Complete code and data are available at \url{https://github.com/Nyx-Dynamics/algorithmic-bias-epidemiology-academic}.

%==============================================================================
\section{Results}
%==============================================================================

\subsection{Baseline System Characteristics}

The 11-barrier model yielded a baseline success probability of $0.0018\%$, indicating that fewer than 2 in 100,000 individuals successfully navigate all barriers to resolve algorithmic discrimination (Table~\ref{tab:barriers}).

\begin{table}[H]
\centering
\caption{Barrier parameters and layer assignments}
\label{tab:barriers}
\begin{tabular}{llcc}
\toprule
Layer & Barrier & Pass Probability & Cost (\$) \\
\midrule
Data Integration & Cross-System Data Sharing & 0.30 & 500 \\
& Multi-Database Flagging & 0.25 & 300 \\
& Rapid Data Transmission & 0.35 & 200 \\
\midrule
Data Accuracy & Error Correction Difficulty & 0.40 & 1,500 \\
& Identity Verification & 0.45 & 800 \\
& Systemic Bias in Algorithms & 0.35 & 2,000 \\
\midrule
Institutional & Legal Knowledge Gap & 0.20 & 3,000 \\
& Financial Resources & 0.25 & 2,500 \\
& Time Constraints & 0.30 & 1,000 \\
& Retaliation Concerns & 0.50 & 500 \\
& Procedural Complexity & 0.35 & 1,200 \\
\midrule
\multicolumn{2}{l}{\textbf{Total}} & \textbf{0.0018\%} & \textbf{\$13,500} \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Individual Barrier Removal Effects}

Counterfactual analysis revealed that removing any single barrier while others remained produced negligible improvement in success probability (Figure~\ref{fig:individual}). All individual effects were $<0.02\%$, with the maximum effect from Legal Knowledge Gap removal at $0.009\%$.

This counterintuitive result arises from the multiplicative structure: removing one barrier still requires passage through 10 others with low probabilities. Mathematically, $P(\text{success}|p_j=1) = \prod_{i \neq j} p_i \approx 0$ when remaining barriers have low pass probabilities.

\subsection{Strategy Comparison}

Five barrier removal strategies were compared: forward (L1$\rightarrow$L2$\rightarrow$L3), backward (L3$\rightarrow$L2$\rightarrow$L1), greedy by marginal impact, greedy by cost-effectiveness, and random ordering (mean of 10 permutations). All strategies exhibited characteristic ``hockey stick'' trajectories with near-zero improvement until removal of final 2--3 barriers, followed by rapid increase to approximately 95\% success (Figure~\ref{fig:stepwise}).

Strategy equivalence (ANOVA: $F=0.23$, $p=0.92$) confirmed that removal ordering is irrelevant; only removal completeness determines outcome.

\subsection{Layer-Level Effects and Interactions}

Factorial analysis of layer removal revealed dramatic interaction effects (Table~\ref{tab:interactions}):

\begin{table}[H]
\centering
\caption{ANOVA decomposition of layer removal effects}
\label{tab:interactions}
\begin{tabular}{lcc}
\toprule
Effect & $\Delta$ Success (\%) & \% of Total \\
\midrule
\textbf{Main Effects} & & \\
\quad Data Integration (L1) & 0.0 & 0.0 \\
\quad Data Accuracy (L2) & 0.0 & 0.0 \\
\quad Institutional (L3) & 0.3 & 0.3 \\
\midrule
\textbf{Two-Way Interactions} & & \\
\quad L1 $\times$ L2 & 3.2 & 3.4 \\
\quad L1 $\times$ L3 & 7.6 & 8.0 \\
\quad L2 $\times$ L3 & 0.5 & 0.5 \\
\midrule
\textbf{Three-Way Interaction} & & \\
\quad L1 $\times$ L2 $\times$ L3 & 83.4 & \textbf{87.6} \\
\midrule
\textbf{Total Effect} & 95.0 & 100.0 \\
\bottomrule
\end{tabular}
\end{table}

The three-way interaction accounted for 87.6\% of total effect variance, indicating that the barriers function as a coordinated system rather than independent obstacles.

\subsection{Shapley Value Attribution}

Shapley decomposition assigned fair responsibility to barriers accounting for interaction structure (Table~\ref{tab:shapley}):

\begin{table}[H]
\centering
\caption{Shapley value attribution for barrier contribution}
\label{tab:shapley}
\begin{tabular}{llc}
\toprule
Layer & Barrier & Shapley Value (\%) \\
\midrule
Institutional & Legal Knowledge Gap & 11.5 \\
Data Integration & Rapid Data Transmission & 10.6 \\
Data Accuracy & Systemic Bias in Algorithms & 10.3 \\
Institutional & Financial Resources & 9.8 \\
Data Integration & Cross-System Data Sharing & 9.4 \\
Institutional & Procedural Complexity & 9.2 \\
Data Accuracy & Error Correction Difficulty & 8.7 \\
Institutional & Time Constraints & 8.5 \\
Data Accuracy & Identity Verification & 8.2 \\
Institutional & Retaliation Concerns & 7.1 \\
Data Integration & Multi-Database Flagging & 6.7 \\
\bottomrule
\end{tabular}
\end{table}

Unlike marginal effects (which approach 0\%), Shapley values reveal true causal contribution by averaging across all possible coalition orderings.

\subsection{Sensitivity Analysis}

\subsubsection{OAT Analysis}

Normalized sensitivity indices showed uniform sensitivity across all barriers ($S_i \approx 1.0$), confirming no single barrier dominates model output.

\subsubsection{Sobol Global Sensitivity}

First-order indices ranged from 0.04 to 0.10; total-order indices clustered around 0.11 (Table~\ref{tab:sobol}). The gap between $S_1$ and $S_T$ ($\approx 0.04$) quantifies each barrier's participation in higher-order interactions.

\begin{table}[H]
\centering
\caption{Sobol sensitivity indices with 95\% confidence intervals}
\label{tab:sobol}
\begin{tabular}{lcccc}
\toprule
Barrier & $S_1$ & $S_1$ CI & $S_T$ & $S_T$ CI \\
\midrule
0 (Cross-System) & 0.099 & $\pm$0.027 & 0.115 & $\pm$0.008 \\
1 (Multi-Database) & 0.065 & $\pm$0.027 & 0.112 & $\pm$0.007 \\
2 (Rapid Transmission) & 0.096 & $\pm$0.026 & 0.120 & $\pm$0.009 \\
3 (Error Correction) & 0.092 & $\pm$0.026 & 0.109 & $\pm$0.008 \\
4 (Identity Verification) & 0.090 & $\pm$0.023 & 0.112 & $\pm$0.008 \\
5 (Systemic Bias) & 0.088 & $\pm$0.024 & 0.114 & $\pm$0.007 \\
6 (Legal Knowledge) & 0.101 & $\pm$0.025 & 0.106 & $\pm$0.008 \\
7 (Financial Resources) & 0.076 & $\pm$0.024 & 0.109 & $\pm$0.007 \\
8 (Time Constraints) & 0.062 & $\pm$0.026 & 0.116 & $\pm$0.007 \\
9 (Retaliation) & 0.045 & $\pm$0.026 & 0.108 & $\pm$0.007 \\
10 (Procedural) & 0.057 & $\pm$0.030 & 0.119 & $\pm$0.008 \\
\bottomrule
\end{tabular}
\end{table}

\subsubsection{Morris Screening}

All barriers exhibited high $\sigma$ values relative to $\mu^*$, confirming substantial nonlinear effects and interaction involvement consistent with the dominant three-way interaction.

\subsubsection{Bootstrap Validation}

Key findings demonstrated 100\% robustness across 1,000 bootstrap samples (Table~\ref{tab:robustness}):

\begin{table}[H]
\centering
\caption{Key finding robustness under bootstrap resampling}
\label{tab:robustness}
\begin{tabular}{lccc}
\toprule
Finding & Threshold & Bootstrap Mean & Robustness \\
\midrule
Three-way interaction dominance & $>70\%$ & 99.6\% & 100.0\% \\
Individual effects near zero & $<1\%$ & 0.0055\% & 100.0\% \\
Barriers for 90\% success & $\geq 10$ & 11.0 & 100.0\% \\
\bottomrule
\end{tabular}
\end{table}

\subsubsection{Signal-to-Noise Analysis}

SNR remained positive ($>$0 dB) until approximately 25\% parameter noise, indicating model conclusions are robust to moderate uncertainty (Figure~\ref{fig:snr}).

\subsection{Population Attributable Fraction}

PAF analysis revealed substantial attributable fractions across vulnerable populations (Table~\ref{tab:paf}):

\begin{table}[H]
\centering
\caption{Population Attributable Fractions for algorithmic discrimination}
\label{tab:paf}
\begin{tabular}{lccc}
\toprule
Population & Exposure ($P_e$) & Relative Risk & PAF \\
\midrule
General Population & 0.40 & 1.5 & 16.7\% \\
PWID & 0.85 & 3.2 & 65.2\% \\
PWH & 0.70 & 2.4 & 49.5\% \\
Justice-Involved & 0.90 & 4.1 & \textbf{73.6\%} \\
\bottomrule
\end{tabular}
\end{table}

Justice-involved individuals show the highest PAF (73.6\%), indicating that nearly three-quarters of their adverse outcomes are attributable to algorithmic factors.

\subsection{Cost-Effectiveness Analysis}

Complete barrier removal (\$13,500) achieved 6.8\% improvement per \$1,000, compared to $<$0.1\% per \$1,000 for partial interventions. Economic analysis strongly supports comprehensive over incremental reform strategies.

%==============================================================================
\section{Discussion}
%==============================================================================

\subsection{Principal Findings}

Our analysis provides mathematical proof that algorithmic discrimination operates as a synergistic system where barriers reinforce each other, rendering incremental reform futile. The dominant three-way interaction (87.6\%) explains why decades of piecemeal policy interventions---each targeting individual barriers---have failed to meaningfully reduce algorithmic discrimination.

The finding that all individual barrier removal effects approach zero has profound policy implications. When advocates or policymakers claim that ``improving credit report accuracy'' or ``providing legal aid'' will address algorithmic discrimination, our analysis proves these interventions are mathematically insufficient in isolation. The system is designed---whether intentionally or emergently---such that partial fixes fail.

\subsection{Epidemiological Parallels}

The barrier synergy we document parallels drug resistance in infectious disease treatment. Just as incomplete antiretroviral therapy selects for resistant HIV strains \citep{volberding2010antiretroviral}, incomplete policy intervention may select for more sophisticated algorithmic discrimination. The ``hockey stick'' trajectory mirrors viral breakthrough: the system remains largely unchanged until a critical threshold of intervention is reached.

Our framework also parallels the integration dynamics of human endogenous retroviruses (HERVs). Once data integrates across interconnected systems, it becomes a permanent feature of the individual's ``digital genome,'' passed to downstream decision-makers just as HERVs are transmitted across generations \citep{coffin2021retrovirology}.

\subsection{Implications for Reform}

The strong three-way interaction supports coordinated, multi-agency reform rather than siloed regulatory approaches. Currently, credit reporting is regulated by the CFPB under FCRA, employment screening by the EEOC under Title VII, and housing by HUD under FHA. Our findings suggest these agencies must coordinate comprehensive intervention to achieve meaningful improvement.

Shapley attribution identifies priority targets when comprehensive reform is infeasible: Legal Knowledge Gap (11.5\%), Rapid Data Transmission (10.6\%), and Systemic Bias (10.3\%) contribute most to the barrier system. Interventions targeting these barriers first---while planning comprehensive reform---may provide marginally greater benefit than random targeting.

\subsection{Sensitivity Analysis Validation}

The 100\% robustness of key findings across bootstrap samples provides strong evidence that our conclusions are not artifacts of parameter choices. The SNR analysis confirms robustness to moderate uncertainty, while the Sobol analysis demonstrates that no single parameter dominates---the system truly operates as an integrated whole.

\subsection{Limitations}

Our model assumes multiplicative independence between barriers, which may underestimate or overestimate certain pathway effects. Pass probabilities were estimated from heterogeneous sources and may vary across populations. We did not model time dynamics or feedback loops, which may amplify long-term effects. Finally, the model represents a stylized abstraction; actual systems may have more or fewer barriers depending on context.

\subsection{Future Directions}

Future work should extend this framework to time-dynamic models incorporating feedback loops, validate barrier parameters through empirical measurement, and develop intervention cost-effectiveness models for policy optimization. The epidemiological framework suggests surveillance systems analogous to disease monitoring may be appropriate for tracking algorithmic discrimination at population scale.

%==============================================================================
\section{Conclusion}
%==============================================================================

Algorithmic discrimination exhibits synergistic barrier dynamics that render incremental reform mathematically futile. The dominant three-way interaction (87.6\%) provides a quantitative explanation for the persistent failure of piecemeal policy interventions. Effective reform requires coordinated, comprehensive action addressing all barrier layers simultaneously. Our findings support treating algorithmic discrimination as a public health emergency warranting population-level intervention.

%==============================================================================
% Acknowledgments
%==============================================================================

\section*{Acknowledgments}

The author thanks the open-source software communities whose tools made this analysis possible.

%==============================================================================
% Funding
%==============================================================================

\section*{Funding}

This work was supported by Nyx Dynamics LLC.

%==============================================================================
% Conflicts of Interest
%==============================================================================

\section*{Declaration of Interests}

The corresponding author (ACD) reports prior employment with Gilead Sciences, Inc.\ from January 2020 through November 2024 and prior ownership of company stock, which was fully divested in December 2024. Gilead Sciences, Inc.\ had no role in the conception, design, analysis, interpretation, or writing of this study, and provided no funding, data, materials, or input into any aspect of the work.

The corresponding author (ACD) is the owner of Nyx Dynamics, LLC, a consulting company providing advisory and fractional leadership services in healthcare, technology, and complex systems. This research was conducted independently, released as open-source work, and was not produced as part of, or in support of, any paid consulting engagement.

No other competing interests are declared.

%==============================================================================
% Data Availability
%==============================================================================

\section*{Data Availability}

All code and data are available at \url{https://github.com/Nyx-Dynamics/algorithmic-bias-epidemiology-academic}.

%==============================================================================
% References
%==============================================================================

\bibliographystyle{unsrtnat}
\begin{thebibliography}{99}

\bibitem[Fuller et al.(2021)]{fuller2021hidden}
Fuller, J.B., Raman, M., et al. (2021).
Hidden Workers: Untapped Talent.
\textit{Harvard Business School Report}.

\bibitem[CFPB(2022)]{cfpb2022}
Consumer Financial Protection Bureau. (2022).
\textit{Consumer Credit Reports: A Study of Medical and Non-Medical Collections}.
Washington, DC.

\bibitem[Obermeyer et al.(2019)]{obermeyer2019dissecting}
Obermeyer, Z., Powers, B., Vogeli, C., \& Mullainathan, S. (2019).
Dissecting racial bias in an algorithm used to manage the health of populations.
\textit{Science}, 366(6464), 447-453.

\bibitem[Coffin \& Hughes(2021)]{coffin2021retrovirology}
Coffin, J.M., \& Hughes, S.H. (2021).
Retroviruses.
In \textit{Fields Virology} (7th ed.). Wolters Kluwer.

\bibitem[Nowak \& May(2000)]{nowak2000virus}
Nowak, M.A., \& May, R.M. (2000).
\textit{Virus Dynamics: Mathematical Principles of Immunology and Virology}.
Oxford University Press.

\bibitem[Volberding \& Deeks(2010)]{volberding2010antiretroviral}
Volberding, P.A., \& Deeks, S.G. (2010).
Antiretroviral therapy and management of HIV infection.
\textit{The Lancet}, 376(9734), 49-62.

\bibitem[Shapley(1953)]{shapley1953value}
Shapley, L.S. (1953).
A value for n-person games.
\textit{Contributions to the Theory of Games}, 2(28), 307-317.

\bibitem[Sobol(2001)]{sobol2001global}
Sobol, I.M. (2001).
Global sensitivity indices for nonlinear mathematical models and their Monte Carlo estimates.
\textit{Mathematics and Computers in Simulation}, 55(1-3), 271-280.

\bibitem[Morris(1991)]{morris1991factorial}
Morris, M.D. (1991).
Factorial sampling plans for preliminary computational experiments.
\textit{Technometrics}, 33(2), 161-174.

\bibitem[Levin(1953)]{levin1953occurrence}
Levin, M.L. (1953).
The occurrence of lung cancer in man.
\textit{Acta Unio Internationalis Contra Cancrum}, 9(3), 531-541.

\bibitem[Herman \& Usher(2017)]{herman2017salib}
Herman, J., \& Usher, W. (2017).
SALib: An open-source Python library for sensitivity analysis.
\textit{Journal of Open Source Software}, 2(9), 97.

\bibitem[Wu \& Mayer(2019)]{wu2019}
Wu, C.C., \& Mayer, R.N. (2019).
Credit reporting agency errors and consumer dispute outcomes.
\textit{Consumer Financial Protection Bureau Research Report}.

\bibitem[EEOC(2012)]{eeoc2012}
Equal Employment Opportunity Commission. (2012).
\textit{Enforcement Guidance on the Consideration of Arrest and Conviction Records}.
Washington, DC.

\bibitem[LSC(2022)]{lsc2022}
Legal Services Corporation. (2022).
\textit{The Justice Gap: The Unmet Civil Legal Needs of Low-Income Americans}.
Washington, DC.

\end{thebibliography}

%==============================================================================
% Figures
%==============================================================================

\newpage
\section*{Figures}

\begin{figure}[H]
\centering
\includegraphics[width=0.9\textwidth]{figures/individual_barrier_effects.png}
\caption{\textbf{Individual barrier removal effects.} Counterfactual analysis showing marginal effect on success probability of removing each barrier while others remain. All effects approach zero, demonstrating the multiplicative blocking structure of the barrier system.}
\label{fig:individual}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.9\textwidth]{figures/stepwise_comparison.png}
\caption{\textbf{Strategy comparison for barrier removal.} All strategies exhibit ``hockey stick'' trajectories with near-zero improvement until final barriers are removed. Strategy equivalence confirms that removal ordering is irrelevant; only completeness matters.}
\label{fig:stepwise}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.9\textwidth]{figures/interaction_heatmap.png}
\caption{\textbf{Layer interaction effects.} Heatmap showing main effects (diagonal) and pairwise interactions (off-diagonal). The dominant three-way interaction (87.6\%, not shown) accounts for majority of total effect.}
\label{fig:heatmap}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.9\textwidth]{figures/sensitivity_analysis.png}
\caption{\textbf{Global sensitivity analysis.} Four-panel analysis: (A) OAT sensitivity indices, (B) Sobol first-order and total-order indices, (C) Morris elementary effects, (D) bootstrap confidence intervals.}
\label{fig:sensitivity}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.9\textwidth]{figures/snr_robustness.png}
\caption{\textbf{Signal-to-noise ratio and key finding robustness.} (A) SNR remains positive up to 25\% noise. (B-D) All key findings demonstrate 100\% robustness across bootstrap samples.}
\label{fig:snr}
\end{figure}

\end{document}
